"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8786],{8404:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>c,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"hpc/ml_ai_hpc/llm_fine_tuning","title":"Fine tune LLMs on HPC","description":"LoRA fine-tuning?","source":"@site/docs/hpc/08_ml_ai_hpc/04_llm_fine_tuning.md","sourceDirName":"hpc/08_ml_ai_hpc","slug":"/hpc/ml_ai_hpc/llm_fine_tuning","permalink":"/rts-docs-dev/pr-preview/pr-66/docs/hpc/ml_ai_hpc/llm_fine_tuning","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-ITS/rts-docs-dev/blob/main/docs/hpc/08_ml_ai_hpc/04_llm_fine_tuning.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"hpcSidebar","previous":{"title":"LLMs on HPC","permalink":"/rts-docs-dev/pr-preview/pr-66/docs/hpc/ml_ai_hpc/llm_on_hpc"},"next":{"title":"Open OnDemand (OOD) with Conda/Singularity","permalink":"/rts-docs-dev/pr-preview/pr-66/docs/hpc/ood/open_on_demand"}}');var o=t(5105),r=t(3881);const s={},c="Fine tune LLMs on HPC",p={},l=[];function a(e){const n={h1:"h1",header:"header",p:"p",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"fine-tune-llms-on-hpc",children:"Fine tune LLMs on HPC"})}),"\n",(0,o.jsx)(n.p,{children:"LoRA fine-tuning?"})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(a,{...e})}):a(e)}},3881:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>c});var i=t(8101);const o={},r=i.createContext(o);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);