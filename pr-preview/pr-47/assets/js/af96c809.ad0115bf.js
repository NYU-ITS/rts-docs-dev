"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8647],{2003:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>l,frontMatter:()=>i,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"srde/user_guide/data_transfers","title":"Managing Data Transfer","description":"Every research project that is using the Secure Research Data Environment (SRDE) must have an assigned Data Steward. The Data Steward is responsible for  ingesting to and egressing data from the secure environment, following the processes described below. Currently, the data steward role cannot be combined with other roles in the project, in other words, a data steward cannot also be a user/researcher in the project.","source":"@site/docs/srde/02_user_guide/03_data_transfers.mdx","sourceDirName":"srde/02_user_guide","slug":"/srde/user_guide/data_transfers","permalink":"/rts-docs-dev/pr-preview/pr-47/docs/srde/user_guide/data_transfers","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/srde/02_user_guide/03_data_transfers.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"srdeSidebar","previous":{"title":"Data Access","permalink":"/rts-docs-dev/pr-preview/pr-47/docs/srde/user_guide/data_access"},"next":{"title":"Troubleshooting","permalink":"/rts-docs-dev/pr-preview/pr-47/docs/srde/user_guide/troubleshooting"}}');var a=t(6070),r=t(385);const i={},o="Managing Data Transfer",c={},d=[{value:"Data Ingestion process",id:"data-ingestion-process",level:2},{value:"Uploading Data to the Staging Area",id:"uploading-data-to-the-staging-area",level:3},{value:"Option1: Using the Web Console Interface",id:"option1-using-the-web-console-interface",level:4},{value:"Option2: Using the CLI",id:"option2-using-the-cli",level:4},{value:"Push Data to the Research Workspace Using Airflow",id:"push-data-to-the-research-workspace-using-airflow",level:3}];function h(e){const s={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.header,{children:(0,a.jsx)(s.h1,{id:"managing-data-transfer",children:"Managing Data Transfer"})}),"\n",(0,a.jsx)(s.p,{children:"Every research project that is using the Secure Research Data Environment (SRDE) must have an assigned Data Steward. The Data Steward is responsible for  ingesting to and egressing data from the secure environment, following the processes described below. Currently, the data steward role cannot be combined with other roles in the project, in other words, a data steward cannot also be a user/researcher in the project."}),"\n",(0,a.jsx)(s.admonition,{title:"Data Steward role",type:"tip",children:(0,a.jsx)(s.p,{children:"The project PI must inform the SRDE team who the assigned Data Steward is for the research project before the project is deployed on the SRDE."})}),"\n",(0,a.jsx)(s.h2,{id:"data-ingestion-process",children:"Data Ingestion process"}),"\n",(0,a.jsxs)(s.p,{children:["Ingesting data into the secure environment is a two-step process; First the Data Steward must upload the data onto the staging GCP Storage Bucket and then \u201cpush\u201d the data into the secure Workspace environment.\n",(0,a.jsx)(s.img,{alt:"Data ingestion process overview",src:t(8170).A+"",width:"681",height:"81"})]}),"\n",(0,a.jsx)(s.h3,{id:"uploading-data-to-the-staging-area",children:"Uploading Data to the Staging Area"}),"\n",(0,a.jsx)(s.h4,{id:"option1-using-the-web-console-interface",children:"Option1: Using the Web Console Interface"}),"\n",(0,a.jsxs)(s.p,{children:["Log into GCP console, set project to your staging project (i.e. srde-staging-dev), and navigate on the side panel to Cloud Storage -> Buckets:\n",(0,a.jsx)(s.img,{alt:"GCP Cloud Storage Buckets",src:t(997).A+"",width:"970",height:"803"})]}),"\n",(0,a.jsxs)(s.p,{children:["Navigate to your research workspace\u2019s corresponding Staging Ingress bucket:\n",(0,a.jsx)(s.img,{alt:"GCP Cloud Storage staging ingress buckets",src:t(5810).A+"",width:"985",height:"425"})]}),"\n",(0,a.jsxs)(s.p,{children:["Copy data to the Staging Ingress bucket:\n",(0,a.jsx)(s.img,{alt:"GCP Cloud Storage copy to ingress bucket",src:t(8320).A+"",width:"1277",height:"633"})]}),"\n",(0,a.jsx)(s.h4,{id:"option2-using-the-cli",children:"Option2: Using the CLI"}),"\n",(0,a.jsx)(s.p,{children:"Follow the instructions in section 2 to install and configure gcloud on your workstation.  Once this is done, run the following command to find your workspace\u2019s bucket:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-sh",children:"gsutil ls | fgrep [Workspace Name]\n"})}),"\n",(0,a.jsx)(s.p,{children:"The workspace name will be given to you by the SRDE team after your workspace has been provisioned.  The command above should output two buckets\u2013 one will be for data ingest (ingress) and the other will be for data egress:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-sh",children:"nyu10003@cloudshell:~ (srde-staging-dev-cedd)$ gsutil ls | fgrep example\ngs://nyu-us-east4-example-staging-egress-9d94/\ngs://nyu-us-east4-example-staging-ingress-4bd9/\n"})}),"\n",(0,a.jsx)(s.p,{children:"To ingest data into the SRDE, run the following command to copy individual files into the ingress bucket:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-sh",children:"gsutil cp [FILENAME] gs://[INGRESS BUCKET]\n"})}),"\n",(0,a.jsx)(s.p,{children:"So for instance, the following command would copy an individual text file (1661-0.txt) into the example ingress bucket:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-sh",children:"gsutil cp 1661-0.txt gs://nyu-us-east4-example-staging-ingress-4bd9/\n"})}),"\n",(0,a.jsx)(s.p,{children:"To copy a folder, you need to add -r after cp:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-sh",children:"gsutil cp -r [FOLDER] gs://[INGRESS BUCKET]\n"})}),"\n",(0,a.jsx)(s.p,{children:"We would use the following command to copy a folder named dataset into the example ingress bucket:"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-sh",children:"gsutil cp -r dataset gs://nyu-us-east4-example-staging-ingress-4bd9/\n"})}),"\n",(0,a.jsx)(s.h3,{id:"push-data-to-the-research-workspace-using-airflow",children:"Push Data to the Research Workspace Using Airflow"}),"\n",(0,a.jsxs)(s.p,{children:["Once the data is in the Staging Ingress bucket, navigate to Cloud Composer and click on Airflow:\n",(0,a.jsx)(s.img,{alt:"Push data using airflow",src:t(7111).A+"",width:"1228",height:"270"})]}),"\n",(0,a.jsxs)(s.p,{children:["In Airflow you will see the DAG workflows for your project. If you do not see any DAGs, contact ",(0,a.jsx)(s.a,{href:"mailto:srde-support@nyu.edu",children:"srde-support@nyu.edu"})," with subject line \u201cMissing Airflow Permissions\u201d\n",(0,a.jsx)(s.img,{alt:"Airflow permissions",src:t(4258).A+"",width:"1722",height:"956"})]}),"\n",(0,a.jsxs)(s.p,{children:["Once you see the workflows for your project, pick the one named ",(0,a.jsx)(s.strong,{children:"[project-id]_Ingress_1_Staging_to_Workspace"}),", which will bring you to the DAG page. On the DAG page, click on the \u201cplay\u201d button at the top right to trigger the DAG:\n",(0,a.jsx)(s.img,{alt:"DAG trigger",src:t(7310).A+"",width:"1115",height:"530"})]}),"\n",(0,a.jsxs)(s.p,{children:["The DAG may take a few minutes to run. You can see its progress in the status display  on the bottom left.\n",(0,a.jsx)(s.img,{alt:"DAG status",src:t(1578).A+"",width:"1115",height:"530"})]}),"\n",(0,a.jsx)(s.p,{children:"The display shows a list of tasks executed by the DAG. A light green square will appear next to the task when it is running, and turn dark green when it is complete. When all tasks have finished successfully, the DAG is done."}),"\n",(0,a.jsx)(s.p,{children:"Researchers will now be able to see the data in the ingress bucket in the research project workspace."}),"\n",(0,a.jsx)(s.admonition,{title:"Access policy for Data Stewards",type:"note",children:(0,a.jsx)(s.p,{children:"Data stewards do not have access to the research project workspace."})}),"\n",(0,a.jsxs)(s.p,{children:["Instructions for researchers who need to access the ingested data in the research workspace are found in the ",(0,a.jsx)(s.a,{href:"/rts-docs-dev/pr-preview/pr-47/docs/srde/user_guide/data_access",children:"Data Access section"})," of this document."]})]})}function l(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},4258:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/airflow_permissions-d312474d9f121152c82d6b487e8a5748.png"},1578:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/dag_status-986386918a90a6b59ef4552a0213469b.png"},7310:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/dag_trigger-cd761b28b57c7db2d04fa6fde03cbb48.png"},8170:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/data_ingestion_process_overview-77a4be2f0e6a383da9c4248eb2fc2e13.png"},997:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/gcp_cloud_storage_buckets-990188b3efdbd33d1bbeaa5814acd373.png"},8320:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/gcp_copy_to_ingress_bucket-8757b3634d5b6b35c99458119551a32a.png"},5810:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/gcp_staging_ingress_bucket-eeb791fac6440c6c7b916c3a89ed453e.png"},7111:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/push_using_airflow-74e2e3826b0ed70246be3383c52b1398.png"},385:(e,s,t)=>{t.d(s,{R:()=>i,x:()=>o});var n=t(758);const a={},r=n.createContext(a);function i(e){const s=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),n.createElement(r.Provider,{value:s},e.children)}}}]);